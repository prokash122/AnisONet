{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcab9dd",
   "metadata": {},
   "source": [
    "Written by Prokash Chandra Roy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65f6851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1aa792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Custom Dataset class for loading 1-channel TIFF images and labels\n",
    "class TiffDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('L')  # Convert to grayscale (1 channel)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to load image {img_path}: {e}\")\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "# Load data from folder and CSV\n",
    "def load_data(image_folder, csv_path):\n",
    "    # Read CSV\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to read CSV {csv_path}: {e}\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    if 'index' not in df.columns or 'class' not in df.columns:\n",
    "        raise ValueError(\"CSV must have 'index' and 'class' columns\")\n",
    "    \n",
    "    # Get image paths and labels, converting integer index to .tiff filename\n",
    "    image_paths = [os.path.join(image_folder, f\"{int(img_name)}.tiff\") for img_name in df['index']]\n",
    "    labels = df['class'].values\n",
    "    \n",
    "    # Validate image paths\n",
    "    missing_images = [img_path for img_path in image_paths if not os.path.exists(img_path)]\n",
    "    if missing_images:\n",
    "        print(f\"Warning: {len(missing_images)} images not found, e.g., {missing_images[:5]}\")\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    \n",
    "    return image_paths, labels, le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37cb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model for 1-channel input\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # 1 input channel\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (IMG_HEIGHT // 8) * (IMG_WIDTH // 8), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dd6f6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 14296, Test set size: 3574\n",
      "Epoch 1/40 — Train Loss: 0.3252, Train Acc: 0.9028 — Val Loss: 0.0477, Val Acc: 0.9910\n",
      "→ Saved best model (Val Acc: 0.9910) at epoch 1\n",
      "Epoch 2/40 — Train Loss: 0.0542, Train Acc: 0.9849 — Val Loss: 0.0560, Val Acc: 0.9877\n",
      "Epoch 3/40 — Train Loss: 0.0280, Train Acc: 0.9915 — Val Loss: 0.0063, Val Acc: 0.9989\n",
      "→ Saved best model (Val Acc: 0.9989) at epoch 3\n",
      "Epoch 4/40 — Train Loss: 0.0063, Train Acc: 0.9990 — Val Loss: 0.0013, Val Acc: 0.9997\n",
      "→ Saved best model (Val Acc: 0.9997) at epoch 4\n",
      "Epoch 5/40 — Train Loss: 0.0072, Train Acc: 0.9987 — Val Loss: 0.0018, Val Acc: 0.9992\n",
      "Epoch 6/40 — Train Loss: 0.0063, Train Acc: 0.9990 — Val Loss: 0.0057, Val Acc: 0.9969\n",
      "Epoch 7/40 — Train Loss: 0.0036, Train Acc: 0.9992 — Val Loss: 0.0103, Val Acc: 0.9983\n",
      "Epoch 8/40 — Train Loss: 0.0038, Train Acc: 0.9993 — Val Loss: 0.0007, Val Acc: 0.9997\n",
      "Epoch 9/40 — Train Loss: 0.0006, Train Acc: 1.0000 — Val Loss: 0.0029, Val Acc: 0.9992\n",
      "Epoch 10/40 — Train Loss: 0.1249, Train Acc: 0.9754 — Val Loss: 0.0201, Val Acc: 0.9941\n",
      "Epoch 11/40 — Train Loss: 0.0121, Train Acc: 0.9971 — Val Loss: 0.0021, Val Acc: 0.9994\n",
      "Epoch 12/40 — Train Loss: 0.0046, Train Acc: 0.9991 — Val Loss: 0.0018, Val Acc: 0.9994\n",
      "Epoch 13/40 — Train Loss: 0.0034, Train Acc: 0.9991 — Val Loss: 0.0004, Val Acc: 1.0000\n",
      "→ Saved best model (Val Acc: 1.0000) at epoch 13\n",
      "Epoch 14/40 — Train Loss: 0.0027, Train Acc: 0.9994 — Val Loss: 0.0008, Val Acc: 0.9994\n",
      "Epoch 15/40 — Train Loss: 0.0054, Train Acc: 0.9985 — Val Loss: 0.0017, Val Acc: 0.9994\n",
      "Epoch 16/40 — Train Loss: 0.0027, Train Acc: 0.9994 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 17/40 — Train Loss: 0.0020, Train Acc: 0.9995 — Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch 18/40 — Train Loss: 0.0021, Train Acc: 0.9997 — Val Loss: 0.0044, Val Acc: 0.9986\n",
      "Epoch 19/40 — Train Loss: 0.0036, Train Acc: 0.9990 — Val Loss: 0.0061, Val Acc: 0.9986\n",
      "Epoch 20/40 — Train Loss: 0.0023, Train Acc: 0.9998 — Val Loss: 0.0005, Val Acc: 0.9997\n",
      "Epoch 21/40 — Train Loss: 0.0017, Train Acc: 0.9994 — Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch 22/40 — Train Loss: 0.0011, Train Acc: 0.9999 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 23/40 — Train Loss: 0.0007, Train Acc: 0.9999 — Val Loss: 0.0024, Val Acc: 0.9994\n",
      "Epoch 24/40 — Train Loss: 0.0012, Train Acc: 0.9998 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 25/40 — Train Loss: 0.0049, Train Acc: 0.9990 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 26/40 — Train Loss: 0.0096, Train Acc: 0.9973 — Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch 27/40 — Train Loss: 0.0014, Train Acc: 0.9997 — Val Loss: 0.0009, Val Acc: 0.9994\n",
      "Epoch 28/40 — Train Loss: 0.0007, Train Acc: 1.0000 — Val Loss: 0.0012, Val Acc: 0.9994\n",
      "Epoch 29/40 — Train Loss: 0.0010, Train Acc: 0.9998 — Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch 30/40 — Train Loss: 0.0009, Train Acc: 0.9998 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 31/40 — Train Loss: 0.0007, Train Acc: 0.9998 — Val Loss: 0.0062, Val Acc: 0.9992\n",
      "Epoch 32/40 — Train Loss: 0.0009, Train Acc: 0.9997 — Val Loss: 0.0010, Val Acc: 0.9994\n",
      "Epoch 33/40 — Train Loss: 0.0003, Train Acc: 0.9999 — Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch 34/40 — Train Loss: 0.0003, Train Acc: 0.9999 — Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch 35/40 — Train Loss: 0.0009, Train Acc: 0.9997 — Val Loss: 0.0047, Val Acc: 0.9994\n",
      "Epoch 36/40 — Train Loss: 0.0004, Train Acc: 1.0000 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 37/40 — Train Loss: 0.0004, Train Acc: 0.9999 — Val Loss: 0.0020, Val Acc: 0.9994\n",
      "Epoch 38/40 — Train Loss: 0.0008, Train Acc: 0.9997 — Val Loss: 0.0000, Val Acc: 1.0000\n",
      "Epoch 39/40 — Train Loss: 0.0657, Train Acc: 0.9885 — Val Loss: 0.0079, Val Acc: 0.9969\n",
      "Epoch 40/40 — Train Loss: 0.0070, Train Acc: 0.9986 — Val Loss: 0.0012, Val Acc: 0.9997\n",
      "Training log saved to: c:\\Users\\proy\\Desktop\\30 April\\Classification - with new rock data\\train_log.csv\n",
      "\n",
      "Loading best model from best_image_classification_model.pth for final evaluation…\n",
      "Final Test Accuracy (Best Model): 1.0000\n",
      "Confusion matrix plot saved to: c:\\Users\\proy\\Desktop\\30 April\\Classification - with new rock data\\confusion_matrix.png\n",
      "Training history plot saved to: c:\\Users\\proy\\Desktop\\30 April\\Classification - with new rock data\\training_history.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def plot_training_history(train_losses,\n",
    "                          val_losses,\n",
    "                          train_accuracies,\n",
    "                          val_accuracies,\n",
    "                          save_path='training_history.png',\n",
    "                          font_size=16):\n",
    "   \n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Loss subplot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses,   label='Validation Loss')\n",
    "    plt.title('Loss',       fontsize=font_size + 2)\n",
    "    plt.xlabel('Epoch',     fontsize=font_size)\n",
    "    plt.ylabel('Loss',      fontsize=font_size)\n",
    "    plt.xticks(fontsize=font_size)\n",
    "    plt.yticks(fontsize=font_size)\n",
    "    plt.legend(fontsize=font_size)\n",
    "\n",
    "    # Accuracy subplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies,   label='Validation Accuracy')\n",
    "    plt.title('Accuracy',      fontsize=font_size + 2)\n",
    "    plt.xlabel('Epoch',        fontsize=font_size)\n",
    "    plt.ylabel('Accuracy',     fontsize=font_size)\n",
    "    plt.xticks(fontsize=font_size)\n",
    "    plt.yticks(fontsize=font_size)\n",
    "    plt.legend(fontsize=font_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Training history plot saved to: {os.path.abspath(save_path)}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true,\n",
    "                          y_pred,\n",
    "                          classes=None,\n",
    "                          save_path='confusion_matrix.png',\n",
    "                          font_size=16):\n",
    "    \"\"\"\n",
    "    y_true, y_pred : lists or arrays of true / predicted labels\n",
    "    classes        : list of class names, e.g. ['Circular','Elliptical','Rock']\n",
    "    font_size      : base font size for ticks, labels, and annotations\n",
    "    \"\"\"\n",
    "    if classes is None:\n",
    "        classes = ['Circular', 'Elliptical', 'Rock']\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='Blues',\n",
    "        xticklabels=classes,\n",
    "        yticklabels=classes,\n",
    "        annot_kws={\"size\": font_size}\n",
    "    )\n",
    "\n",
    "    plt.title('Confusion Matrix', fontsize=font_size + 2)\n",
    "    plt.xlabel('Predicted Label',    fontsize=font_size)\n",
    "    plt.ylabel('True Label',         fontsize=font_size)\n",
    "\n",
    "    plt.xticks(fontsize=font_size, rotation=45)\n",
    "    plt.yticks(fontsize=font_size, rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Confusion matrix plot saved to: {os.path.abspath(save_path)}\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Paths and filenames\n",
    "    image_folder      = 'training/all'\n",
    "    csv_path          = 'training.csv'\n",
    "    best_model_path   = 'best_image_classification_model.pth'\n",
    "    final_model_path  = 'final_image_classification_model.pth'\n",
    "    log_csv_path      = 'train_log.csv'\n",
    "\n",
    "    # 1. Load data\n",
    "    image_paths, labels, label_encoder = load_data(image_folder, csv_path)\n",
    "\n",
    "    # 2. Train/test split\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        image_paths, labels,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=labels\n",
    "    )\n",
    "    print(f\"Training set size: {len(train_paths)}, Test set size: {len(test_paths)}\")\n",
    "\n",
    "    # 3. Transforms & datasets\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "    train_dataset = TiffDataset(train_paths, train_labels, transform=transform)\n",
    "    test_dataset  = TiffDataset(test_paths,  test_labels,  transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 4. Model, loss, optimizer\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    model       = CNN(num_classes).to(DEVICE)\n",
    "    criterion   = nn.CrossEntropyLoss()\n",
    "    optimizer   = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 5. Training loop\n",
    "    best_val_acc = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # — train —\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc  = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # — validate —\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total   += labels.size(0)\n",
    "\n",
    "        val_loss = val_loss / len(test_loader)\n",
    "        val_acc  = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} — \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} — \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"→ Saved best model (Val Acc: {best_val_acc:.4f}) at epoch {epoch+1}\")\n",
    "\n",
    "    # 6. Save training log\n",
    "    df = pd.DataFrame({\n",
    "        'epoch':      np.arange(1, EPOCHS + 1),\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss':   val_losses,\n",
    "        'train_acc':  train_accuracies,\n",
    "        'val_acc':    val_accuracies,\n",
    "    })\n",
    "    df.to_csv(log_csv_path, index=False)\n",
    "    print(f\"Training log saved to: {os.path.abspath(log_csv_path)}\")\n",
    "\n",
    "    # 7. Load best model & evaluate on test\n",
    "    print(f\"\\nLoading best model from {best_model_path} for final evaluation…\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    test_accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Final Test Accuracy (Best Model): {test_accuracy:.4f}\")\n",
    "\n",
    "    # 8. Generate plots with custom labels and font size\n",
    "    plot_confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        classes=['Circular', 'Elliptical', 'Rock'],\n",
    "        save_path='confusion_matrix.png',\n",
    "        font_size=16\n",
    "    )\n",
    "    plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "    # 9. Save final model & encoder\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    np.save('label_encoder_classes.npy', label_encoder.classes_)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prokash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
